library(swirl)
swirl()
my_vector<-c(1:20)
my_vector<-1:20
my_vector
dim(my_vector)
lenght(my_vector)
length(my_vector)
dim(my_vector)<-c(4,5)
dim(my_vector)
attributes(my_vector)
my_vector
class(my_vector)
my_matrix<-my_vector
?matrix()
?matrix
my_matrix2(1:20,4,5)
my_matrix2<-matrix(1:20,4,5)
identical(my_matrix,my_matrix2)
patients<-c("Bill","Gina","Kelly","Sean")
cbind(patients,my_matrix)
my_data<-data.frame(patients,my_matrix)
my_data
class(my_data)
cnames<-c("patients","age","weight","bp","rating","test")
cnames<-c("patient","age","weight","bp","rating","test")
colnames(my_data,cnames)
colnames(cnames)
colnames(my_data)<-cnames
my_data
True==true
T=T
TRUE==TRUE
(FALSE==TRUE)==FALSE
6==7
6<7
10<=10
5!=7
5!=7
!5==7
FALSE&FALSE
TRUE & C(TRUE,FALSE,FALSE)
TRUE & c(TRUE,FALSE,FALSE)
TRUE && c(TRUE,FALSE,FALSE)
TRUE | c(TRUE,FALSE,FALSE)
TRUE || c(TRUE,FALSE,FALSE)
5>8||6!=8&&4>3.9
isTRUE(6>4)
identical('twins','twins')
xor(5==6, !FALSE)
ints<-sample(10)
ints
ints>5
which(ints)
which(ints>7)
any(ints<0)
all(ints>0)
head(flags)
dim(flags)
class(flags)
cls_list<-lapply(flags,class)
cls_list
class(cls_list)
as.character(cls_list)
cls_vect<-sapply(flags,class)
class(cls_vect)
sum(flags$orange)
flags_colors<-flags[,11:17]
flag_colors<-flags[,11:17]
head(flag_colors)
lapply(flag_colors,sum)
sapply(flag_colors,sum)
sapply(flag_colors,mean)
flag_shapes<-flags[,19:23]
lapply(flag_shapes,range)
sapply(flag_shapes,range)
shape_mat<-sapply(flag_shapes,range)
shape_mat
class(shape_mat)
unique(c(3,4,5,5,6,6))
unique(c(3,4,5,5,5,6,6))
lapply(flags,unique)
unique_vals<-lapply(flags,unique)
unique_vals
sapply(unique_vals,length)
sapply(unique_vals,length)
sapply(flags,unique)
lapply(unique_vals, function(elem) elem[2])
sapply(flags, unique)
vapply(flags,unique,numeric(1))
ok()
sapply(flags,class)
vapply(flags,class,charecter(1))
vapply(flags,class,character(1))
?tapply
table(flags$landmass)
table(flags$animate)
tapply(flags$animate,flags$landmass,mean)
tapply(flags$population,flags$red,summary)
tapply(flags$population,flags$landmass,summary)
ls(plants)
ls()
class(plants)
dim(plants)
nrows(plants)
nrow(plants)
ncol(plants)
object.size(plants)
names(plants)
head(plants)
head(plants,10)
tail(plants,15)
summary(plants)
table(plants$Active_Growth_period)
table(plants$Active_Growth_Period)
str()
str(plants)
?sample
sample(1:6,4,replace=T)
sample(1:6,4,replace=TRUE)
sample(1:6,4,replace=TRUE)
sample(1:20,10)
LETTERS
sample(LETTERS)
flips<-sample(c(0,1),100,replace=TRUE,prob=c(.3,.7))
flips
sum(flips)
?rbinom
rbinom(1,size=100,prob=0.7)
flips2<-rbinom(100,size=1,prob=0.7)
flips2
sum(flips2)
?rnorm
rnorm(10)
rnorm(10,mean=100,sd=25)
rpois(5)
?rpois
rpois(5,10)
my_pois<-replicate(100,rpois(5,10))
my_pois
cm<-colMeans(my_pois)
hist(cm)
d1<-Sys.Date()
class(d1)
unclass(d1)
d1
d2<-as.Date("1969-01-01")
unclass(d2)
t1<-Sys.time()
t1
class(t1)
unclass(t1)
POSIXlt((Sys.time()))
POSIXlt(Sys.time())
t2<-as.POSIXlt(Sys.time())
class(t2)
t2
unclass(t2)
str(unclass(t2)
)
t2$min
weekdays(d1)
months(t1)
quarter(t2)
quarters(t2)
t3<-"October 17, 1986 08:24"
t4<-strptime(t3, "%B %d,%Y %H:%M")
t4<-strptime(t3, "%B %d, %Y %H:%M")
t4
class(t4)
Sys.time()>t1
Sys.time()-t1
difftime(Sys.time(), t1, units = 'days'
)
x <- c(0.18, -1.54, 0.42, 0.95)
w <- c(2, 1, 3, 1)
z <- x*w
mean(z)
z
x <- c(0.8, 0.47, 0.51, 0.73, 0.36, 0.58, 0.57, 0.85, 0.44, 0.42)
y <- c(1.39, 0.72, 1.55, 0.48, 1.19, -1.59, 1.23, -0.65, 1.49, 0.05)
fit.origin <- lm( y ~ x - 1 )
summary(fit.origin)
data(mtcars)
coef(lm(mtcars$mpg~mtcars$wt))
x <- c(8.58, 10.46, 9.01, 9.64, 8.86)
m.x <- mean(x)
sd.x <- sd(x)
(x[1] - m.x)/sd.x
x <- c(0.8, 0.47, 0.51, 0.73, 0.36, 0.58, 0.57, 0.85, 0.44, 0.42)
y <- c(1.39, 0.72, 1.55, 0.48, 1.19, -1.59, 1.23, -0.65, 1.49, 0.05)
lm( y ~ x )
x <- c(0.8, 0.47, 0.51, 0.73, 0.36, 0.58, 0.57, 0.85, 0.44, 0.42)
mean(x)
Rtools
?Rtools
install.packages("Rtools")
library(manipulate)
manipulate(plot(1:x), x=slider(1,100))
install.packages("devtools")
shiny
?shiny
library(manipulate)
myPlot <- function(s) {
plot(cars$dist - mean(cars$dist), cars$speed - mean(cars$speed))
abline(0, s)
}
myplot
myPlot
slider
?slider
manipulate(myPlot(s), s = slider(0, 2, step = 0.1))
library(shiny)
shinyUI(pageWithSidebar(
headerPanel("Data science FTW!"),
sidebarPanel(
h2('Big text')
h3('Sidebar')
),
mainPanel(
h3('Main Panel text')
)
))
example(anscombe)
x <- c(0.61, 0.93, 0.83, 0.35, 0.54, 0.16, 0.91, 0.62, 0.62)
y <- c(0.67, 0.84, 0.6, 0.18, 0.85, 0.47, 1.1, 0.65, 0.36)
fit <- lm(y~x)
summary(fit)
e <- resid(fit)
sqe <- e*e
res.var <- sum(sqe) / (length(e) - 2)
sqrt(res.var)
x<-mtcars$wt
y<-mtcars$mpg
fit<-lm(y ~ x)
predict(fit,data.frame(x=mean(x)), interval="confidence")
?mtcars
predict(fit,data.frame(x=3), interval="prediction")
x<-mtcars$wt*0.5
fit<-lm(y~x)
fit
fit2<-lm(y~I(x/2))
tbl2<-summary(fit2)$coefficients
mn<-tbl2[2,1]      #mean is the estimated slope
std_err<-tbl2[2,2] #standard error
deg_fr<-fit2$df    #degree of freedom
#Two sides T-Tests
mn + c(-1,1) * qt(0.975,df=deg_fr) * std_err
l = lm(y ~ x)
lm(y ~ I(x + 10))
l
modelA = mean(y)
modelB = lm(y ~ x)
sum((modelB$fitted.values - y)^2) / sum((modelA - y)^2)
modelC = lm(y ~ x - 1)
sum(modelC$fitted.values - y)
library(devtools)
install_github('slidify','ramnathv')
install_github('slidifyLibraries','ramnathv')
data(mtcars)
fit <- lm(mpg ~ factor(cyl) + wt, data = mtcars)
fit
fit2 <- lm(mpg ~ factor(cyl), mtcars)
summary(fit2)
data(mtcars)
fit1 <- lm(mpg ~ factor(cyl) + wt, data = mtcars)
fit2 <- lm(mpg ~ factor(cyl) + wt + interaction(cyl, wt), data = mtcars)
compare <- anova(fit1, fit2)
compare$Pr
fit3 <- lm(mpg ~ factor(cyl)*wt, mtcars)
summary(fit3)
lm(mpg ~ I(wt * 0.5) + factor(cyl), data = mtcars)
x <- c(0.586, 0.166, -0.042, -0.614, 11.72)
y <- c(0.549, -0.026, -0.127, -0.751, 1.344)
fit <- lm(y ~ x)
lm.influence(fit)$hat
hatvalues(fit)
x <- c(0.586, 0.166, -0.042, -0.614, 11.72)
y <- c(0.549, -0.026, -0.127, -0.751, 1.344)
fit <- lm(y~x)
lm.influence(fit)$hat
dfbetas(fit)
sort(round(dfbeta(fit)[,2],3))
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
library(rpart)
install.packages(rattle)
set.seed(125)
inTrain <- createDataPartition(y = segmentationOriginal$Case, list = FALSE)
train <- subset(segmentationOriginal, Case == "Train")
test <- subset(segmentationOriginal, Case == "Test")
modFit <- train(Class ~ ., data = train, method = "rpart")
modFit$finalModel
plot(modFit$finalModel, uniform = TRUE, main = "Classification Tree")
text(modFit$finalModel, use.n = TRUE, all = TRUE, cex = .8)
fancyRpartPlot(modFit$finalModel)
fancyRpartPlot(modFit)
predict(modFit, newdata = train)
install.packages("rattle")
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
library(rpart)
install.packages(rattle)
set.seed(125)
inTrain <- createDataPartition(y = segmentationOriginal$Case, list = FALSE)
train <- subset(segmentationOriginal, Case == "Train")
test <- subset(segmentationOriginal, Case == "Test")
modFit <- train(Class ~ ., data = train, method = "rpart")
modFit$finalModel
plot(modFit$finalModel, uniform = TRUE, main = "Classification Tree")
text(modFit$finalModel, use.n = TRUE, all = TRUE, cex = .8)
fancyRpartPlot(modFit$finalModel)
fancyRpartPlot(modFit)
predict(modFit, newdata = train)
install.packages("e1071")
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
library(rpart)
install.packages(rattle)
set.seed(125)
inTrain <- createDataPartition(y = segmentationOriginal$Case, list = FALSE)
train <- subset(segmentationOriginal, Case == "Train")
test <- subset(segmentationOriginal, Case == "Test")
modFit <- train(Class ~ ., data = train, method = "rpart")
modFit$finalModel
plot(modFit$finalModel, uniform = TRUE, main = "Classification Tree")
text(modFit$finalModel, use.n = TRUE, all = TRUE, cex = .8)
fancyRpartPlot(modFit$finalModel)
fancyRpartPlot(modFit)
predict(modFit, newdata = train)
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
library(rpart)
library(rattle)
set.seed(125)
inTrain <- createDataPartition(y = segmentationOriginal$Case, list = FALSE)
train <- subset(segmentationOriginal, Case == "Train")
test <- subset(segmentationOriginal, Case == "Test")
modFit <- train(Class ~ ., data = train, method = "rpart")
modFit$finalModel
plot(modFit$finalModel, uniform = TRUE, main = "Classification Tree")
text(modFit$finalModel, use.n = TRUE, all = TRUE, cex = .8)
fancyRpartPlot(modFit$finalModel)
fancyRpartPlot(modFit)
predict(modFit, newdata = train)
?rattle
?fancyRpartPlot
plot(modFit$finalModel, uniform = TRUE, main = "Classification Tree")
text(modFit$finalModel, use.n = TRUE, all = TRUE, cex = .8)
fancyRpartPlot(modFit$finalModel)
fancyRpartPlot(modFit)
install.packages("rpart")
install.packages("rpart")
install.packages("rpart")
plot(modFit$finalModel, uniform = TRUE, main = "Classification Tree")
text(modFit$finalModel, use.n = TRUE, all = TRUE, cex = .8)
fancyRpartPlot(modFit$finalModel)
fancyRpartPlot(modFit)
install.packages("rpart.plot")
plot(modFit$finalModel, uniform = TRUE, main = "Classification Tree")
text(modFit$finalModel, use.n = TRUE, all = TRUE, cex = .8)
fancyRpartPlot(modFit$finalModel)
fancyRpartPlot(modFit)
install.packages(c("digest", "httr", "RColorBrewer", "RCurl", "reshape2", "shiny", "tidyr"))
install.packages("fancyRpartPlot")
install.packages("fancyRpartPlot")
install.packages("fancyRpartPlot")
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
library(rpart)
library(rattle)
set.seed(125)
inTrain <- createDataPartition(y = segmentationOriginal$Case, list = FALSE)
train <- subset(segmentationOriginal, Case == "Train")
test <- subset(segmentationOriginal, Case == "Test")
modFit <- train(Class ~ ., data = train, method = "rpart")
modFit$finalModel
plot(modFit$finalModel, uniform = TRUE, main = "Classification Tree")
text(modFit$finalModel, use.n = TRUE, all = TRUE, cex = .8)
fancyRpartPlot(modFit$finalModel)
fancyRpartPlot(modFit)
predict(modFit, newdata = train)
library(caret)
library(pgmm)
data(olive)
olive = olive[,-1]
library(randomForest)
model <- train(Area ~ ., data = olive, method = "rpart2")
newdata = as.data.frame(t(colMeans(olive)))
predict(model, newdata = newdata)
install.packages("pgmm")
library(caret)
library(pgmm)
data(olive)
olive = olive[,-1]
library(randomForest)
model <- train(Area ~ ., data = olive, method = "rpart2")
newdata = as.data.frame(t(colMeans(olive)))
predict(model, newdata = newdata)
library(ElemStatLearn)
data(SAheart)
set.seed(8484)
train = sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA = SAheart[train,]
testSA = SAheart[-train,]
model <- train(chd ~ age + alcohol + obesity + tobacco + typea + ldl,
data = trainSA, method = "glm", family = "binomial")
missClass = function(values,prediction){sum(((prediction > 0.5)*1) != values)/length(values)}
missClass(testSA$chd, predict(model, newdata = testSA))
missClass(trainSA$chd, predict(model, newdata = trainSA))
install.packages("ElemStatLearn")
ibrary(ElemStatLearn)
data(SAheart)
set.seed(8484)
train = sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA = SAheart[train,]
testSA = SAheart[-train,]
set.seed(13234)
model <- train(chd ~ age + alcohol + obesity + tobacco + typea + ldl,
data = trainSA, method = "glm", family = "binomial")
missClass = function(values,prediction){sum(((prediction > 0.5)*1) != values)/length(values)}
missClass(testSA$chd, predict(model, newdata = testSA))
missClass(trainSA$chd, predict(model, newdata = trainSA))
library(ElemStatLearn)
data(SAheart)
set.seed(8484)
train = sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA = SAheart[train,]
testSA = SAheart[-train,]
set.seed(13234)
model <- train(chd ~ age + alcohol + obesity + tobacco + typea + ldl,
data = trainSA, method = "glm", family = "binomial")
missClass = function(values,prediction){sum(((prediction > 0.5)*1) != values)/length(values)}
missClass(testSA$chd, predict(model, newdata = testSA))
missClass(trainSA$chd, predict(model, newdata = trainSA))
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
vowel.train$y <- factor(vowel.train$y)
vowel.test$y <- factor(vowel.test$y)
set.seed(33833)
a <- randomForest(y ~ ., data = vowel.train, importance = FALSE)
b <- varImp(a)
order(b)
install.packages("randomForest")
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
vowel.train$y <- factor(vowel.train$y)
vowel.test$y <- factor(vowel.test$y)
set.seed(33833)
a <- randomForest(y ~ ., data = vowel.train, importance = FALSE)
b <- varImp(a)
order(b)
library(ElemStatLearn)
library(randomForest)
data(vowel.train)
data(vowel.test)
vowel.train$y <- factor(vowel.train$y)
vowel.test$y <- factor(vowel.test$y)
set.seed(33833)
a <- randomForest(y ~ ., data = vowel.train, importance = FALSE)
b <- varImp(a)
order(b)
model = train(y ~ ., data = vowel.train, method = "rf")
model$finalModel$importance[order(-model$finalModel$importance),]
varImp(model)
setwd("~/R/DevDataProd-CourseProject")
shiny::runApp()
shiny::runApp()
install.packages("base64enc")
devtools::install_github('ramnathv/rCharts')
shiny::runApp()
transition: rotate
fread
?fread
shiny::runApp()
date: `r date()`
transition: rotate
Storm Database Explorer
========================================================
type: sub-section
This presentation is being created as part of the peer assessment for the coursera developing data products class. The assignment is geared toward ensuring the following concepts were well understood by the students
- **shiny** to build data product application
- **R-Presentation or slidify** to create data product related presentations
The Application
========================================================
type: sub-section
To display the understanding of using **shiny** to build an application, a simple application called **Storm Database Explorer** has been developed and deployed at:
https://senthilkumar-k.shinyapps.io/DevDataProd-CourseProject/
The application allows the user to:
- Select the inputs like- the range of years, types of events.
- Select the output to be displayed on the map, or as a graph, or as a table
- Also has a option to download the filtered data.
The Data
========================================================
type: sub-section
Developing Data Products - Course Project
========================================================
